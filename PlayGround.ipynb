{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentProcessing.pdf_processing import pdf_processor\n",
    "from DocumentProcessing.pdf_processing import paper_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_paper = \"/root/gpt_projects/ABoringKnowledgeManagementSystem/DocumentProcessing/tests/1810.04805.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text, title,publish_display_data, authors, abstract, references = paper_processor.extract_text_from_pdf(pdf_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = pdf_processor.extract_text(pdf_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_processor.extract_toc_from_pdf(pdf_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text_2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_processor.extract_pdf_metadata(pdf_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_processor.py\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, max_non_text_pages=10):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = ''\n",
    "        non_text_page_count = 0\n",
    "\n",
    "        for page in doc:\n",
    "            page_text = page.get_text()\n",
    "            if not page_text:\n",
    "                non_text_page_count += 1\n",
    "                if non_text_page_count >= max_non_text_pages:\n",
    "                    raise ValueError(\"PDF contains too many non-text pages. Please use your own OCR tool first.\")\n",
    "                continue\n",
    "            else:\n",
    "                non_text_page_count = 0  # Reset counter if a text page is found\n",
    "            text += page_text\n",
    "\n",
    "        return text\n",
    "\n",
    "def extract_toc_from_pdf(pdf_path, max_non_text_pages=10):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        toc = doc.get_toc(simple=False)\n",
    "        non_text_page_count = 0\n",
    "\n",
    "        # Check for non-text pages in the document\n",
    "        for page in doc:\n",
    "            if not page.get_text():\n",
    "                non_text_page_count += 1\n",
    "                if non_text_page_count >= max_non_text_pages:\n",
    "                    raise ValueError(\"PDF contains too many non-text pages. Please use your own OCR tool first.\")\n",
    "                continue\n",
    "            else:\n",
    "                non_text_page_count = 0  # Reset counter if a text page is found\n",
    "                break  # Break the loop after finding the first text page\n",
    "\n",
    "        return toc\n",
    "\n",
    "\n",
    "def extract_notes_from_pdf(pdf_path):\n",
    "    notes = []\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page in doc:\n",
    "            annotations = page.annots()\n",
    "            if annotations:\n",
    "                for annot in annotations:\n",
    "                    annot_text = annot.info['content']\n",
    "                    if annot_text:\n",
    "                        notes.append(annot_text)\n",
    "    return notes\n",
    "\n",
    "\n",
    "def extract_pdf_metadata(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        metadata = doc.metadata\n",
    "    return metadata\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    pass\n",
    "\n",
    "\n",
    "def extract_pdf_metadata(file_path):\n",
    "    \"\"\"\n",
    "    Extracts metadata from a PDF file.\n",
    "    Args:\n",
    "    file_path (str): Path to the PDF file.\n",
    "    Returns:\n",
    "    dict: Metadata of the PDF.\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        metadata = pdf.metadata\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentManagement.Elastic import IndexSettingsGenerator,search_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    ['https://localhost:9200'],\n",
    "    http_auth=('elastic', 'dR8dVIqQ5=i3pPSH00zC'),  # Replace with your credentials\n",
    "    verify_certs=True,\n",
    "    ca_certs='/root/http_ca.crt'  # Path to your CA certificate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "\n",
    "parsed = parser.from_file(pdf_paper)\n",
    "print(parsed[\"metadata\"])  # To print the metadata of the document.\n",
    "print(parsed[\"content\"])   # To print the text content of the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import re\n",
    "\n",
    "def extract_text_tika(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file using Apache Tika, page by page, and checks for consecutive pages without text.\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file.\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are page numbers and values are extracted text from each page.\n",
    "    Raises:\n",
    "        ValueError: If 10 consecutive pages are found without text.\n",
    "    \"\"\"\n",
    "    # Parse the PDF file\n",
    "    parsed = parser.from_file(file_path)\n",
    "\n",
    "    # Extract the content\n",
    "    content = parsed['content']\n",
    "    if not content:\n",
    "        raise ValueError(\"No content found in the PDF file.\")\n",
    "\n",
    "    # Split the content into pages\n",
    "    pages = content.split('\\f')  # Splitting by form feed character which typically represents page breaks\n",
    "    text = {}\n",
    "    consecutive_pages_without_text = 0\n",
    "\n",
    "    for i, page_content in enumerate(pages, 1):\n",
    "        # Clean up whitespace\n",
    "        page_text = ' '.join(page_content.strip().split())\n",
    "\n",
    "        if not page_text:\n",
    "            consecutive_pages_without_text += 1\n",
    "            if consecutive_pages_without_text == 10:\n",
    "                raise ValueError(\"PDF seems to contain only images. Please use OCR first.\")\n",
    "        else:\n",
    "            consecutive_pages_without_text = 0\n",
    "\n",
    "        text[i] = page_text\n",
    "\n",
    "    return text\n",
    "\n",
    "# Usage\n",
    "# file_path = 'path_to_your_pdf_file.pdf'\n",
    "# pdf_text = extract_text_tika(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import re\n",
    "\n",
    "def extract_text_tika(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file using Apache Tika, page by page, and checks for consecutive pages without text.\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file.\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are page numbers and values are extracted text from each page.\n",
    "    Raises:\n",
    "        ValueError: If 10 consecutive pages are found without text.\n",
    "    \"\"\"\n",
    "    # Parse the PDF file\n",
    "    parsed = parser.from_file(file_path)\n",
    "\n",
    "    # Extract the content\n",
    "    content = parsed['content']\n",
    "    if not content:\n",
    "        raise ValueError(\"No content found in the PDF file.\")\n",
    "\n",
    "    # Split the content into pages\n",
    "    pages = content.split('\\f')  # Splitting by form feed character which typically represents page breaks\n",
    "    text = {}\n",
    "    consecutive_pages_without_text = 0\n",
    "\n",
    "    for i, page_content in enumerate(pages, 1):\n",
    "        # Clean up whitespace\n",
    "        page_text = ' '.join(page_content.strip().split())\n",
    "\n",
    "        if not page_text:\n",
    "            consecutive_pages_without_text += 1\n",
    "            if consecutive_pages_without_text == 10:\n",
    "                raise ValueError(\"PDF seems to contain only images. Please use OCR first.\")\n",
    "        else:\n",
    "            consecutive_pages_without_text = 0\n",
    "\n",
    "        text[i] = page_text\n",
    "\n",
    "    return text\n",
    "\n",
    "# Usage\n",
    "# file_path = 'path_to_your_pdf_file.pdf'\n",
    "# pdf_text = extract_text_tika(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import re\n",
    "\n",
    "def extract_text_tika(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file using Apache Tika, page by page, and checks for consecutive pages without text.\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file.\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are page numbers and values are extracted text from each page.\n",
    "    Raises:\n",
    "        ValueError: If 10 consecutive pages are found without text.\n",
    "    \"\"\"\n",
    "    # Parse the PDF file\n",
    "    parsed = parser.from_file(file_path)\n",
    "    content = parsed['content']\n",
    "\n",
    "    # Split the content by pages - Tika's plain text output may not provide clear page delimiters\n",
    "    # Adjust the splitting logic based on the actual output format\n",
    "    pages = content.split('some_page_delimiter')  # Replace 'some_page_delimiter' with the actual delimiter used by Tika\n",
    "\n",
    "    text = {}\n",
    "    consecutive_pages_without_text = 0\n",
    "\n",
    "    for i, page_content in enumerate(pages, start=1):\n",
    "        page_text = page_content.strip()\n",
    "\n",
    "        if not page_text:\n",
    "            consecutive_pages_without_text += 1\n",
    "            if consecutive_pages_without_text == 10:\n",
    "                raise ValueError(\"10 consecutive pages without text found. PDF may contain only images. Please use OCR.\")\n",
    "        else:\n",
    "            consecutive_pages_without_text = 0\n",
    "\n",
    "        text[i] = page_text\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = extract_text_tika(pdf_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from io import BytesIO\n",
    "\n",
    "def add_invisible_markers(pdf_path, marker):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    for i in range(len(reader.pages)):\n",
    "        page = reader.pages[i]\n",
    "        packet = BytesIO()\n",
    "        can = canvas.Canvas(packet, pagesize=letter)\n",
    "        can.setFontSize(1)  # Setting font size to 1 or 0 to make it nearly invisible\n",
    "        can.drawString(0, 0, marker)  # Position at bottom-left; can adjust as needed\n",
    "        can.save()\n",
    "\n",
    "        packet.seek(0)\n",
    "        new_pdf = PdfReader(packet)\n",
    "        page.merge_page(new_pdf.pages[0])\n",
    "        writer.add_page(page)\n",
    "\n",
    "    with open(\"/root/gpt_projects/ABoringKnowledgeManagementSystem/DocumentProcessing/tests/modified_pdf.pdf\", \"wb\") as f:\n",
    "        writer.write(f)\n",
    "\n",
    "add_invisible_markers(pdf_paper ,\"__PageBreak__12345__\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "\n",
    "def extract_pages_with_tika(file_path, marker):\n",
    "    parsed = parser.from_file(file_path)\n",
    "    content = parsed['content']\n",
    "    pages = content.split(marker)  # Splitting text using the marker\n",
    "\n",
    "    text_by_page = {i+1: page.strip() for i, page in enumerate(pages)}\n",
    "    return text_by_page\n",
    "\n",
    "text_by_page = extract_pages_with_tika(\"/root/gpt_projects/ABoringKnowledgeManagementSystem/DocumentProcessing/tests/modified_pdf.pdf\", \"__PageBreak__12345__\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = pdf_processor.extract_text(pdf_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_page[1], full_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentIndexing.MongoDB import documentstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = documentstore.get_document_from_collection('research_paper', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CHAT_BOT_STATUT_CACHE_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m PAGE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDF VIEWER\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump( PAGE, \u001b[38;5;28mopen\u001b[39m(\u001b[43mCHAT_BOT_STATUT_CACHE_PATH\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m ) )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CHAT_BOT_STATUT_CACHE_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "PAGE = \"PDF VIEWER\"\n",
    "pickle.dump( PAGE, open(CHAT_BOT_STATUT_CACHE_PATH, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (CHAT_BOT_STATUT_CACHE_PATH, 'rb') as fp:\n",
    "    itemlist = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_BOT_STATUT_CACHE_PATH = \"/root/gpt_projects/ABoringKnowledgeManagementSystem/WebApp/WebUI/static/chat_bot_statut_cache/chat_bot_statut_cache.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_VIEWER_CACHE_PATH = \"/root/gpt_projects/ABoringKnowledgeManagementSystem/WebApp/WebUI/static/pdf_viewer_cache/pdf_viewer_cache.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_FILE = ('d42a0cd9-fdfd-4639-a38c-a85b08cd37a7','research_paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('b6a53d7f-ab4a-4d4c-bff3-172c2877e67b', 'research_paper')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( PDF_FILE, open(PDF_VIEWER_CACHE_PATH, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (PDF_VIEWER_CACHE_PATH, 'rb') as fp:\n",
    "    itemlist = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentIndexing.Elastic import IndexSettingsGenerator\n",
    "from DocumentIndexing.Elastic import search_engine\n",
    "from elasticsearch.helpers import scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "\n",
    "def save_research_papers_to_json():\n",
    "    # Connect to MongoDB (Update 'your_connection_string' with your actual connection string)\n",
    "    client = MongoClient(MONGODB_HOST)\n",
    "    replace_string = '/root/gpt_projects/ABoringKnowledgeManagementSystem/DocumentBank'\n",
    "    # Select the database and collection\n",
    "    db = client[MONGODB_DB]# Replace 'your_database_name' with your actual database name\n",
    "    collection = db['research_paper']\n",
    "    \n",
    "    # Query the collection for the needed fields\n",
    "    papers = collection.find({}, {'document_title': 1, 'file_path': 1, 'upload_date': 1, '_id': 0}).sort('upload_date', -1)\n",
    "    \n",
    "    # Format the data into the specified dictionary format\n",
    "    research_papers_dict = {\"research_paper\": [(paper['document_title'], paper['file_path'].replace(replace_string,'/media')) for paper in papers]}\n",
    "    \n",
    "    print(research_papers_dict)\n",
    "    with open(DOCUMENT_FILE_LIST_CACHE_PATH, 'w') as f:\n",
    "        json.dump(research_papers_dict, f)\n",
    "    client.close()\n",
    "# Remember to replace 'your_connection_string' and 'your_database_name'\n",
    "# with the actual connection string to your MongoDB instance and database name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'research_paper': [('Retrieve Anything To Augment Large Language Models', '/media/research_paper/175982bd-df8d-4ef1-be93-256ed527b7f5.pdf'), ('Orca 2: Teaching Small Language Models How to Reason', '/media/research_paper/6eaf87a4-e5fa-482b-8007-d978c784c8f1.pdf'), ('Attention Is All You Need', '/media/research_paper/45b39be6-3fb7-4658-afa9-8ba7c8cb47de.pdf'), ('BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', '/media/research_paper/b6a53d7f-ab4a-4d4c-bff3-172c2877e67b.pdf')]}\n"
     ]
    }
   ],
   "source": [
    "save_research_papers_to_json()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentIndexing.Embedding.embedding import TextEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentIndexing.Elastic.search_engine import SearchEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = SearchEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.search_for_terms('research_paper_chunk_level','bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chat import rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rag.two_step_retrival_page(\"what is BERT?\",\"2610a7e7-359f-4e79-85d8-d3e3dff51dab\", \"research_paper\",return_top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag.two_step_prompt_page(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = rag.one_document_prompt(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexsetting = IndexSettingsGenerator.GeneralIndexSettings(EMBEDDING_DINENSION)\n",
    "chunk_mapping = indexsetting.chunk_level_mapping()\n",
    "document_mapping = indexsetting.document_level_mapping()\n",
    "page_mapping = indexsetting.page_level_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16796/2026850524.py:2: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  es = Elasticsearch(hosts=ES_HOST, http_auth=ES_HTTP_AUTH, verify_certs=True, ca_certs=ES_CA_CERTS_PATH)\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(hosts=ES_HOST, http_auth=ES_HTTP_AUTH, verify_certs=True, ca_certs=ES_CA_CERTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mappings': {'properties': {'document_id_elastic': {'type': 'keyword'}, 'document_id_universal': {'type': 'keyword'}, 'page_number': {'type': 'integer'}, 'chunk_number': {'type': 'integer'}, 'upload_date': {'type': 'date', 'format': 'epoch_millis'}, 'max_split_number': {'type': 'integer'}, 'text_piece': {'type': 'text'}, 'language': {'type': 'keyword'}, 'text_piece_vector': {'type': 'dense_vector', 'dims': 1024}, 'metadata': {'type': 'object', 'dynamic': True}, 'document_tags': {'type': 'keyword'}, 'related_documents': {'type': 'object', 'dynamic': True}, 'acheived': {'type': 'boolean'}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16796/1163721322.py:4: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  response = es.indices.delete(index=f'research_paper_'+level, ignore=[400, 404])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mappings': {'properties': {'document_id_elastic': {'type': 'keyword'}, 'document_id_universal': {'type': 'keyword'}, 'page_number': {'type': 'integer'}, 'upload_date': {'type': 'date', 'format': 'epoch_millis'}, 'max_split_number': {'type': 'integer'}, 'text_piece': {'type': 'text'}, 'language': {'type': 'keyword'}, 'page_summary': {'type': 'text'}, 'page_smmary_vector': {'type': 'dense_vector', 'dims': 1024}, 'text_piece_vector': {'type': 'dense_vector', 'dims': 1024}, 'metadata': {'type': 'object', 'dynamic': True}, 'document_tags': {'type': 'keyword'}, 'related_documents': {'type': 'object', 'dynamic': True}, 'acheived': {'type': 'boolean'}}}}\n",
      "{'mappings': {'properties': {'document_id_elastic': {'type': 'keyword'}, 'document_id_universal': {'type': 'keyword'}, 'upload_date': {'type': 'date', 'format': 'epoch_millis'}, 'max_page_number': {'type': 'integer'}, 'document_title': {'type': 'keyword'}, 'document_summary': {'type': 'text'}, 'language': {'type': 'keyword'}, 'document_title_vector': {'type': 'dense_vector', 'dims': 1024}, 'document_summary_vector': {'type': 'dense_vector', 'dims': 1024}, 'text_piece_vector': {'type': 'dense_vector', 'dims': 1024}, 'metadata': {'type': 'object', 'dynamic': True}, 'document_tags': {'type': 'keyword'}, 'related_documents': {'type': 'object', 'dynamic': True}, 'acheived': {'type': 'boolean'}}}}\n"
     ]
    }
   ],
   "source": [
    "new_search_engine = search_engine.SearchEngine()    \n",
    "for mapping,level in zip([chunk_mapping, page_mapping,document_mapping],DOCUMENT_LEVEL):\n",
    "    print(mapping)\n",
    "    response = es.indices.delete(index=f'research_paper_'+level, ignore=[400, 404])\n",
    "    new_search_engine.create_index(index_name=f'research_paper_'+level, index_settings=mapping)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleasticengine = search_engine.SearchEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_name in DOCUMENT_TYPE:\n",
    "    eleasticengine.create_index(index_name,mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"research_paper_chunk_level\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import scan\n",
    "\n",
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch(hosts=ES_HOST, http_auth=ES_HTTP_AUTH, verify_certs=True, ca_certs=ES_CA_CERTS_PATH)\n",
    "# Index name\n",
    "index_name = \"research_paper\"\n",
    "\n",
    "# Initialize the scan\n",
    "results = scan(es, index=index_name, query={\"query\": {\"match_all\": {}}})\n",
    "\n",
    "# Iterate over the results\n",
    "for doc in results:\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import DOCUMENT_TYPE, ES_HOST, ES_HTTP_AUTH, ES_CA_CERTS_PATH, EMBEDDING_DINENSION,DOCUMENT_LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(hosts=ES_HOST, http_auth=ES_HTTP_AUTH, verify_certs=True, ca_certs=ES_CA_CERTS_PATH)\n",
    "\n",
    "\n",
    "existing_indices = DOCUMENT_TYPE\n",
    "# Delete each index\n",
    "for index in existing_indices:\n",
    "    response = es.indices.delete(index=index)\n",
    "    print(f\"Deleted index: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = embedding_local.embeddings_multilingual(\"ﬁnetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = eleasticengine.vector_search(\"research_paper\",vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdftitle\n",
    "print(pdftitle.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdftitle import get_title_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '/root/gpt_projects/ABoringKnowledgeManagementSystem/DocumentBank/research_paper/416f1ec4-bcbd-4204-9069-b6ea86c1b7a9.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    title = get_title_from_file(fp)\n",
    "    print(f\"The extracted title is: {title}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'DocumentBank/research_paper/2610a7e7-359f-4e79-85d8-d3e3dff51dab.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp= \"/root/downloads/MY_CV_Final.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentManagement.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document(file_path = 'DocumentBank/research_paper/2610a7e7-359f-4e79-85d8-d3e3dff51dab.pdf',document_type='research_paper',document_id='123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentProcessing.pdf_processing import pdf_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_processor.extract_pdf_metadata(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_processor.structured_metadata_for_paper(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_hub.file.unstructured import UnstructuredReader\n",
    "\n",
    "loader = UnstructuredReader()\n",
    "documents = loader.load_data(file=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.ingestion import IngestionPipeline\n",
    "from llama_index.node_parser import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = IngestionPipeline(transformations=[TokenTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=20,\n",
    "    separator=\" \",\n",
    ")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.text_splitter import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pipeline.run(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.text_splitter import TokenTextSplitter\n",
    "\n",
    "splitter = TokenTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=20,\n",
    "    separator=\" \",\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "es = Elasticsearch(hosts=ES_HOST, http_auth=ES_HTTP_AUTH, verify_certs=True, ca_certs=ES_CA_CERTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.elasticsearch import ElasticsearchEmbedding\n",
    "from llama_index.vector_stores import ElasticsearchStore\n",
    "from llama_index import ServiceContext, StorageContext, VectorStoreIndex\n",
    "\n",
    "\n",
    "\n",
    "from llama_index.vector_stores import ElasticsearchStore\n",
    "\n",
    "vector_store = ElasticsearchStore(\n",
    "    index_name= index_name,\n",
    "    es_client=es,     \n",
    "    vwctor_field=\"text_piece_vector\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'We also undertake systematic study of “data contamination” – growing problem when training high capacity models\\non datasets such as Common Crawl which can potentially include content from test datasets simply because such\\ncontent often exists on the web In this paper we develop systematic tools to measure data contamination and quantify\\nits distorting effects Although we ﬁnd that data contamination has minimal effect on GPT’ performance on most\\ndatasets we do identify few datasets where it could be inﬂating results and we either do not report results on these\\ndatasets or we note them with an asterisk depending on the severity\\nIn addition to all the above we also train series of smaller models ranging from 125 million parameters to 13 billion\\nparameters in order to compare their performance to GPT in the zero one and fewshot settings Broadly for most\\ntasks we ﬁnd relatively smooth scaling with model capacity in all three settings one notable pattern is that the gap\\nbetween zero one and fewshot performance often grows with model capacity perhaps suggesting that larger models\\nare more proﬁcient metalearners\\nFinally given the broad spectrum of capabilities displayed by GPT we discuss concerns about bias fairness and\\nbroader societal impacts and attempt preliminary analysis of GPT’ characteristics in this regard\\nThe remainder of this paper is organized as follows In Section we describe our approach and methods for training\\nGPT and evaluating it Section presents results on the full range of tasks in the zero one and fewshot settings\\nSection addresses questions of data contamination traintest overlap Section discusses limitations of GPT\\nSection discusses broader impacts Section reviews related work and Section concludes\\n Approach\\nOur basic pretraining approach including model data and training is similar to the process described in RWC19\\nwith relatively straightforward scaling up of the model size dataset size and diversity and length of training Our use\\nof incontext learning is also similar to RWC19 but in this work we systematically explore different settings for\\nlearning within the context Therefore we start this section by explicitly deﬁning and contrasting the different settings\\nthat we will be evaluating GPT on or could in principle evaluate GPT on These settings can be seen as lying on \\nspectrum of how much taskspeciﬁc data they tend to rely on Speciﬁcally we can identify at least four points on this\\nspectrum see Figure for an illustration\\n• FineTuning FT has been the most common approach in recent years and involves updating the weights of\\n pretrained model by training on supervised dataset speciﬁc to the desired task Typically thousands to\\nhundreds of thousands of labeled examples are used The main advantage of ﬁnetuning is strong performance\\non many benchmarks The main disadvantages are the need for new large dataset for every task the potential\\nfor poor generalization outofdistribution MPL19 and the potential to exploit spurious features of the\\ntraining data GSL18 NK19 potentially resulting in an unfair comparison with human performance In\\nthis work we do not ﬁnetune GPT because our focus is on taskagnostic performance but GPT can be\\nﬁnetuned in principle and this is promising direction for future work\\n• FewShot FS is the term we will use in this work to refer to the setting where the model is given few\\ndemonstrations of the task at inference time as conditioning RWC19 but no weight updates are allowed\\nAs shown in Figure for typical dataset an example has context and desired completion for example\\nan English sentence and the French translation and fewshot works by giving examples of context and\\ncompletion and then one ﬁnal example of context with the model expected to provide the completion We\\ntypically set in the range of 10 to 100 as this is how many examples can ﬁt in the model’ context window\\nnctx 2048 The main advantages of fewshot are major reduction in the need for taskspeciﬁc data and\\nreduced potential to learn an overly narrow distribution from large but narrow ﬁnetuning dataset The main\\ndisadvantage is that results from this method have so far been much worse than stateoftheart ﬁnetuned\\nmodels Also small amount of task speciﬁc data is still required As indicated by the name fewshot\\nlearning as described here for language models is related to fewshot learning as used in other contexts in\\nML HYC01 VBL16 – both involve learning based on broad distribution of tasks in this case implicit in\\nthe pretraining data and then rapidly adapting to new task\\n• OneShot 1S is the same as fewshot except that only one demonstration is allowed in addition to natural\\nlanguage description of the task as shown in Figure The reason to distinguish oneshot from fewshot and\\nzeroshot below is that it most closely matches the way in which some tasks are communicated to humans\\nFor example when asking humans to generate dataset on human worker service for example Mechanical\\nTurk it is common to give one demonstration of the task By contrast it is sometimes difﬁcult to communicate\\nthe content or format of task if no examples are given'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentIndexing.Embedding import embedding_toolkits\n",
    "from DocumentIndexing.Embedding import text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_toolkits.w2v_token_len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_toolkits.token_length(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter.split_text_with_langchain(text,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "token = model.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(token['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "encoded_input = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoded_input['input_ids'][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([token for token in input_ids if token not in tokenizer.all_special_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, model_name=\"sentence-transformers/distiluse-base-multilingual-cased-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter.maximum_tokens_per_chunk = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter.count_tokens(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/distiluse-base-multilingual-cased-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split= splitter.split_text(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter.count_tokens(text=split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load your SentenceTransformer model\n",
    "model_name = \"sentence-transformers/distiluse-base-multilingual-cased-v2\"  # Replace with your model name\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Access the underlying Hugging Face model\n",
    "hf_model = model._first_module().auto_model\n",
    "\n",
    "# Check the maximum input length\n",
    "max_length = hf_model.config.max_position_embeddings\n",
    "print(\"Maximum input token limit:\", max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacypdfreader.spacypdfreader import pdf_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = pdf_reader('/root/gpt_projects/ABoringKnowledgeManagementSystem/DocumentBank/research_paper/06063c65-7cc9-4065-8c26-03d8d7aa6379.pdf', nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.page(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = []\n",
    "for i in range (1,2):\n",
    "    for token in doc._.page(i):\n",
    "        if token.text.endswith('\\n'):\n",
    "        # Remove the line break and do not add a space\n",
    "            new_text += token.text.rstrip('\\n')\n",
    "        else:\n",
    "            # Add token text with a following space\n",
    "            new_text += token.text_with_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for token in list(doc._.page(1).sents):\n",
    "    if token.text.endswith('\\n'):\n",
    "        # Remove the line break and do not add a space\n",
    "        new_text += token.text.rstrip('\\n')\n",
    "    else:\n",
    "        # Add token text with a following space\n",
    "        new_text += token.text_with_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = list(doc._.page(1).sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents[0].text_with_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer\n",
    "for page_layout in extract_pages('/root/gpt_projects/ABoringKnowledgeManagementSystem/DocumentBank/research_paper/06063c65-7cc9-4065-8c26-03d8d7aa6379.pdf'):\n",
    "    for element in page_layout:\n",
    "        if isinstance(element, LTTextContainer):\n",
    "            print(element.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentProcessing.pdf_processing import pdf_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor  = pdf_processor.PDFProcessor('/root/gpt_projects/ABoringKnowledgeManagementSystem/DocumentBank/research_paper/06063c65-7cc9-4065-8c26-03d8d7aa6379.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = processor.extract_text_from_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentIndexing.Embedding import text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter = text_splitter.TextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter.split_text_with_langchain_recursive(pages[1],128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter.split_text_with_langchain_sentence_transformers(pages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentIndexing.Embedding.embedding_toolkits import token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_sentences(sentences, max_tokens=128):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_token_count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the sentence and count the tokens\n",
    "        token_count = token_length(sentence.text)\n",
    "\n",
    "        # If adding this sentence exceeds the max token count, start a new chunk\n",
    "        if current_token_count + token_count > max_tokens:\n",
    "            if current_chunk:  # Ensure current chunk is not empty\n",
    "                chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [sentence.text]\n",
    "            current_token_count = token_count\n",
    "        else:\n",
    "            # Add the sentence to the current chunk\n",
    "            current_chunk.append(sentence.text)\n",
    "            current_token_count += token_count\n",
    "\n",
    "    # Add the last chunk if it's not empty\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_sentences(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[chunks.replace('\\n', '') for chunks in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_sentences_with_sentence_overlap(sentences, max_tokens=128, overlap=0):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_token_count = 0\n",
    "    overlap_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        token_count = token_length(sentence)\n",
    "\n",
    "        if current_token_count + token_count > max_tokens:\n",
    "            if current_chunk:  # Ensure current chunk is not empty\n",
    "                chunks.append(' '.join(current_chunk))\n",
    "            # Start new chunk with overlap from previous chunk\n",
    "            current_chunk = overlap_sentences + [sentence]\n",
    "            current_token_count = len(' '.join(current_chunk).split())\n",
    "            # Update overlap sentences\n",
    "            overlap_sentences = current_chunk[-overlap:] if len(current_chunk) > overlap else current_chunk[:]\n",
    "        else:\n",
    "            # Add the sentence to the current chunk\n",
    "            current_chunk.append(sentence)\n",
    "            current_token_count += token_count\n",
    "            # Update overlap sentences\n",
    "            if len(current_chunk) > overlap:\n",
    "                overlap_sentences = current_chunk[-overlap:]\n",
    "\n",
    "    # Add the last chunk if it's not empty\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_o = chunk_sentences(sents, overlap=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[chunks.replace('\\n', '') for chunks in chunks_o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_sentences_with_sentence_overlap_generator(sentences, max_tokens=128, overlap=0):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_token_count = 0\n",
    "    overlap_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        token_count = token_length(sentence.text)\n",
    "\n",
    "        if current_token_count + token_count > max_tokens:\n",
    "            if current_chunk:\n",
    "                chunks.append(' '.join(current_chunk))\n",
    "            # Start new chunk with overlap from previous chunk\n",
    "            current_chunk = overlap_sentences + [sentence.text]\n",
    "            current_token_count = len(' '.join(current_chunk).split())\n",
    "            # Prepare overlap sentences for next chunk\n",
    "            overlap_sentences = current_chunk[-overlap:] if len(current_chunk) > overlap else current_chunk[:]\n",
    "        else:\n",
    "            current_chunk.append(sentence.text)\n",
    "            current_token_count += token_count\n",
    "            if len(current_chunk) > overlap:\n",
    "                overlap_sentences = current_chunk[-overlap:]\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_g = chunk_sentences_with_sentence_overlap_generator(doc._.page(1).sents, overlap=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[chunks.replace('\\n', '') for chunks in chunks_g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/codebox39/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from DocumentIndexing.Embedding.text_splitter import TextSplitter_Spacy\n",
    "from DocumentProcessing.pdf_processing.pdf_processor import SpacyPdfProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "spacy_processor = SpacyPdfProcessor('/root/gpt_projects/ABoringKnowledgeManagementSystem/WebApp/d42a0cd9-fdfd-4639-a38c-a85b08cd37a7.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = spacy_processor.extract_text_from_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter = TextSplitter_Spacy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = spliter.chunk_sentences_with_sentence_overlap(pages[1], 128,overlap=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3202 guA 2  ]LC. sc [  7v26730. 6071:viXraProvided proper attribution is provided, Google hereby grants permission toreproduce the tables and figures in this paper solely for use in journalistic orscholarly works. Attention Is All You Need',\n",
       " 'Attention Is All You Need Ashish Vaswani∗Google Brainavaswani@google.comNoam Shazeer∗Google Brainnoam@google.comNiki Parmar∗Google Researchnikip@google.comJakob Uszkoreit∗Google Researchusz@google.comLlion Jones∗Google Researchllion@google.comAidan N. Gomez∗ †University of Torontoaidan@cs.toronto.eduŁukasz Kaiser∗Google Brainlukaszkaiser@google.comIllia Polosukhin∗ ‡illia.polosukhin@gmail.com AbstractThe dominant sequence transduction models are based on complex recurrent orconvolutional neural networks that include an encoder and a decoder. The bestperforming models also connect the encoder and decoder through an attentionmechanism.',\n",
       " 'The bestperforming models also connect the encoder and decoder through an attentionmechanism. We propose a new simple network architecture, the Transformer,based solely on attention mechanisms, dispensing with recurrence and convolutionsentirely. Experiments on two machine translation tasks show these models tobe superior in quality while being more parallelizable and requiring significantlyless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, includingensembles, by over 2 BLEU.',\n",
       " 'Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, includingensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,our model establishes a new single-model state-of-the-art BLEU score of 41.8 aftertraining for 3.5 days on eight GPUs, a small fraction of the training costs of thebest models from the literature. We show that the Transformer generalizes well toother tasks by applying it successfully to English constituency parsing both withlarge and limited training data. ∗Equal contribution. Listing order is random.',\n",
       " 'Listing order is random. Jakob proposed replacing RNNs with self-attention and startedthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models andhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-headattention and the parameter-free position representation and became the other person involved in nearly everydetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase andtensor2tensor.',\n",
       " 'Niki designed, implemented, tuned and evaluated countless model variants in our original codebase andtensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, andefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of andimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively acceleratingour research. †Work performed while at Google Brain. ‡Work performed while at Google Research. 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\x0c']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Figure 1: The Transformer - model architecture.\\n\\n',\n",
       " 'The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n\\n3.1 Encoder and Decoder Stacks\\n\\nEncoder: The encoder is composed of a stack of N = 6 identical layers.',\n",
       " 'Each layer has two\\nsub-layers.',\n",
       " 'The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network.',\n",
       " 'We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [1].',\n",
       " 'That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself.',\n",
       " 'To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\n\\n',\n",
       " 'Decoder:',\n",
       " 'The decoder is also composed of a stack of N = 6 identical layers.',\n",
       " 'In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack.',\n",
       " 'Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization.',\n",
       " 'We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions.',\n",
       " 'This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n\\n3.2 Attention\\n\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors.',\n",
       " 'The output is computed as a weighted sum\\n\\n3\\n\\n\\x0c']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Figure 1: The Transformer - model architecture. The Transformer follows this overall architecture using stacked self-attention and point-wise, fullyconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,respectively.3.1 Encoder and Decoder StacksEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has twosub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-wise fully connected feed-forward network. We employ a residual connection [11] around each ofthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer isLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layeritself. To facilitate these residual connections, all sub-layers in the model, as well as the embeddinglayers, produce outputs of dimension dmodel = 512. Decoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the twosub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-headattention over the output of the encoder stack. Similar to the encoder, we employ residual connectionsaround each of the sub-layers, followed by layer normalization. We also modify the self-attentionsub-layer in the decoder stack to prevent positions from attending to subsequent positions. Thismasking, combined with fact that the output embeddings are offset by one position, ensures that thepredictions for position i can depend only on the known outputs at positions less than i.3.2 AttentionAn attention function can be described as mapping a query and a set of key-value pairs to an output,where the query, keys, values, and output are all vectors. The output is computed as a weighted sum3\\x0c']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_generator = spacy_processor.generate_senteces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(spacy_processor.first,spacy_processor.last+1):\n",
    "    print(spliter.chunk_sentences_with_sentence_overlap(next(page_generator)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_generator = spacy_processor.generate_senteces_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_nb, page = next(page_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = spliter.chunk_sentences_with_sentence_overlap_generator(page, 128,overlap=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_nb,split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DocumentManagement.documents import PDFDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = PDFDocument(file_path = '/root/gpt_projects/ABoringKnowledgeManagementSystem/DocumentBank/research_paper/06063c65-7cc9-4065-8c26-03d8d7aa6379.pdf',document_type='research_paper',document_id='123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = arxiv.Client()\n",
    "\n",
    "search_by_id = arxiv.Search(id_list=[\"1706.03762\"])\n",
    "# Reuse client to fetch the paper, then print its title.\n",
    "first_result = list(client.results(search_by_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_result[0].categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_valid_arxiv_id(arxiv_id):\n",
    "    # Regular expression pattern for arXiv IDs\n",
    "    # Format: arXiv:YYMM.number{vV}\n",
    "    # YYMM - two-digit year and month\n",
    "    # number - zero-padded sequence number, 4-digits from 0704 to 1412, 5-digits from 1501 onwards\n",
    "    # vV - optional version number\n",
    "    pattern = r'(\\d{2})(\\d{2})\\.(\\d{4,5})(v\\d+)?$'\n",
    "    \n",
    "    match = re.match(pattern, arxiv_id)\n",
    "    if not match:\n",
    "        return False\n",
    "\n",
    "    # Extract year and month to handle the change in number length\n",
    "    year, month, _, _ = match.groups()\n",
    "    year, month = int(year), int(month)\n",
    "\n",
    "    # Check the number of digits in 'number' based on year and month\n",
    "    if year == 14 and month <= 12 or year < 14:\n",
    "        return len(match.group(3)) == 4  # Should be 4 digits\n",
    "    else:\n",
    "        return len(match.group(3)) == 5  # Should be 5 digits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_valid_arxiv_id(\"1501.00001v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# list of sentences\n",
    "sentences = ['sentence_0', 'sentence_1', ...]\n",
    "\n",
    "# init embedding model\n",
    "## sentence-trnasformers支持有更新，请注意先删除本地模型缓存：\"`SENTENCE_TRANSFORMERS_HOME`/maidalun1020_bce-embedding-base_v1\"或“～/.cache/torch/sentence_transformers/maidalun1020_bce-embedding-base_v1”\n",
    "model = SentenceTransformer(\"maidalun1020/bce-embedding-base_v1\",use_auth_token=\"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\")\n",
    "\n",
    "# extract embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(split, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# init reranker model\n",
    "r_model = CrossEncoder('/root/.cache/huggingface/hub/models--maidalun1020--bce-reranker-base_v1/snapshots/eaa31a577a0574e87a08959bd229ca14ce1b5496', max_length=512)\n",
    "\n",
    "\n",
    "# calculate scores of sentence pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = r_model.predict(('What is BLEU score', 'BLEU score is a metric for evaluating a generated sentence to a reference sentence.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import CrossEncoder\n",
    "import os\n",
    "\n",
    "# Replace 'your_token' with your actual Hugging Face access token\n",
    "\n",
    "\n",
    "# Authenticate with Hugging Face\n",
    "model_name = 'maidalun1020/bce-reranker-base_v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token='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')\n",
    "model = AutoModel.from_pretrained(model_name, use_auth_token='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')\n",
    "\n",
    "# Initialize CrossEncoder with the loaded model and tokenizer\n",
    "cross_encoder = CrossEncoder(model, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import file_utils\n",
    "\n",
    "cache_dir = file_utils.default_cache_path\n",
    "print(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 19 files: 100%|██████████| 19/19 [00:00<00:00, 83886.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing colbert_linear and sparse_linear---------\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "model = BGEM3FlagModel('BAAI/bge-m3',  use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mencode(split, return_dense\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_colbert_vecs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "output_1 = model.encode(split, return_dense=True, return_sparse=False, return_colbert_vecs=False,max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense_vecs': array([[-0.03202487,  0.02325126, -0.04159369, ...,  0.01847978,\n",
       "         -0.03722385,  0.05963242]], dtype=float32),\n",
       " 'lexical_weights': None,\n",
       " 'colbert_vecs': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/codebox39/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# init embedding model\n",
    "## sentence-trnasformers支持有更新，请注意先删除本地模型缓存：\"`SENTENCE_TRANSFORMERS_HOME`/maidalun1020_bce-embedding-base_v1\"或“～/.cache/torch/sentence_transformers/maidalun1020_bce-embedding-base_v1”\n",
    "model = SentenceTransformer('BAAI/bge-m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.encode(['test1','test2'], normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "EMBEDDING_API_URL = \"http://localhost:5000/embeddings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"text_list\": ['test sentence 1', 'test sentence 2'],\n",
    "    \"embedding_type\": \"local\"  # or \"oai\" if you want to use the OpenAI API\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(EMBEDDING_API_URL, json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = response.json()[\"embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(v).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'research_paper' : [\n",
    "        ('ORCA2','/media/research_paper/6eaf87a4-e5fa-482b-8007-d978c784c8f1.pdf'),\n",
    "        ('BERT','/media/research_paper/b6a53d7f-ab4a-4d4c-bff3-172c2877e67b.pdf'),\n",
    "    ]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/gpt_projects/ABoringKnowledgeManagementSystem/WebApp/WebUI/static/document_list_cache/documents.json', 'w') as f:\n",
    "    json.dump(d, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
